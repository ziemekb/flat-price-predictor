{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_DFjz7DqI8Wl"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from joblib import parallel_backend\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jLmsytfyVxq7"
   },
   "outputs": [],
   "source": [
    "PROJECT_ROOT = Path().resolve().parent\n",
    "DATA_PATH = PROJECT_ROOT / 'data' / 'data.csv'\n",
    "\n",
    "def load_data():\n",
    "    df = pd.read_csv(DATA_PATH, delimiter=';')\n",
    "    data = gpd.GeoDataFrame(df, crs=\"epsg:4326\", geometry=[Point(xy) for xy in zip(df.Longitude, df.Latitude)])\n",
    "    data = data.drop(['Latitude', 'Longitude'], axis=1)\n",
    "    data.drop_duplicates(inplace=True)\n",
    "    data.insert(2, 'PricePerSqM', (data['Price'] / data['Area']))\n",
    "    return data\n",
    "\n",
    "data = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fHDo5-LmX7Bm",
    "outputId": "a0b63218-c16e-4389-f7a7-969daec21ad7"
   },
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:.0f}'.format\n",
    "print(data.describe(include=np.number, percentiles=[0.25, 0.75]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "JJeqwNc1LEmE",
    "outputId": "566c4999-b2a3-4bf8-db02-51af50814159"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 12))\n",
    "\n",
    "plt.subplot(3, 2, 1)\n",
    "sns.histplot(data['Price'], bins=30, kde=True)\n",
    "plt.title('Distribution of Price')\n",
    "\n",
    "plt.subplot(3, 2, 2)\n",
    "sns.boxplot(data=data, x='Price')\n",
    "plt.title('Boxplot of Price')\n",
    "\n",
    "plt.subplot(3, 2, 3)\n",
    "sns.histplot(data['Area'], bins=30, kde=True)\n",
    "plt.title('Distribution of Area')\n",
    "\n",
    "plt.subplot(3, 2, 4)\n",
    "sns.boxplot(data=data,  x='Area')\n",
    "plt.title('Boxplot of Area')\n",
    "\n",
    "plt.subplot(3, 2, 5)\n",
    "sns.histplot(data['PricePerSqM'], bins=30, kde=True)\n",
    "plt.title('Distribution of Price Per Sqauare Meter')\n",
    "\n",
    "plt.subplot(3, 2, 6)\n",
    "sns.boxplot(data=data,  x='PricePerSqM')\n",
    "plt.title('Boxplot of Price Per Sqauare Meter')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3vIktn71LWcu"
   },
   "source": [
    "We've identified there are outliers in our data. Thankfully, 70 million PLN for a flat is not a valid amount in Wroc≈Çaw yet. To ensure our sample remains unbiased, let's remove the outliers using interquartile range method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J_e9DKRUhIV1"
   },
   "source": [
    "Besides that we can also observe right skewness of our data. In order to normalize our dataset I'll be using logarithmic transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "BSOOrcFb_Jif",
    "outputId": "69bcd96c-048b-4cb0-d45b-9104cdb05eeb"
   },
   "outputs": [],
   "source": [
    "data = load_data()\n",
    "\n",
    "def iqr_method(series, log=True, verbose=False):\n",
    "    if log:\n",
    "        series = np.log(series + 0.01)\n",
    "    Q1 = np.percentile(series, 10)\n",
    "    Q3 = np.percentile(series, 90)\n",
    "    # interquartile range\n",
    "    IQR = Q3 - Q1\n",
    "    lower = Q1 - 1.5 * IQR\n",
    "    upper = Q3 + 1.5 * IQR\n",
    "    # print the range if verbose\n",
    "    if log and verbose:\n",
    "        print(np.exp(lower))\n",
    "        print(np.exp(upper))\n",
    "    elif verbose:\n",
    "        print(lower)\n",
    "        print(upper)\n",
    "    return lower, upper\n",
    "\n",
    "lower, upper = iqr_method(data['Price'])\n",
    "\n",
    "plt.figure(figsize=(10, 15))\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "sns.histplot(np.log(data['Price']), bins=100)\n",
    "plt.title('Log Price')\n",
    "\n",
    "ax = plt.subplot(3, 1, 2)\n",
    "sns.histplot(np.log(data['Price']), bins=100)\n",
    "plt.title('Log Price Restricted')\n",
    "ax.axvspan(min(np.log(data['Price'])), lower, facecolor='red', alpha=0.25)\n",
    "ax.axvspan(upper, max(np.log(data['Price'])), facecolor='red', alpha=0.25)\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "sns.histplot(data['Price'], bins=100)\n",
    "plt.title('Price')\n",
    "\n",
    "# floor_no is restricted by the website\n",
    "outlier_cols = [('Price', True), ('Area', True), ('PricePerSqM', True), ('Rooms_num', True), ('Build_year', False), ('Floors_num', True), ('Rent', True)]\n",
    "verbose = False\n",
    "for col, log in outlier_cols:\n",
    "    lower, upper = iqr_method(data[col][data[col].notna()], log, verbose)\n",
    "    series = np.log(data[col]) if log else data[col]\n",
    "    data = data[data[col].isna() | series.between(lower, upper)]\n",
    "\n",
    "print(data.describe(include=np.number))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K7wN0ppBWH4k"
   },
   "source": [
    "In the example above, we applied a log transformation to the price data. The red areas represent the rejected outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8q9h2ssLR0FU",
    "outputId": "b43e0e02-f6d9-46ae-b160-1ea56e2112c7"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 12))\n",
    "\n",
    "plt.subplot(3, 2, 1)\n",
    "sns.histplot(data['Price'], bins=30, kde=True)\n",
    "plt.title('Distribution of Price')\n",
    "\n",
    "plt.subplot(3, 2, 2)\n",
    "sns.boxplot(data=data, x='Price')\n",
    "plt.title('Boxplot of Price')\n",
    "\n",
    "plt.subplot(3, 2, 3)\n",
    "sns.histplot(data['Area'], bins=30, kde=True)\n",
    "plt.title('Distribution of Area')\n",
    "\n",
    "plt.subplot(3, 2, 4)\n",
    "sns.boxplot(data=data,  x='Area')\n",
    "plt.title('Boxplot of Area')\n",
    "\n",
    "plt.subplot(3, 2, 5)\n",
    "sns.histplot(data['PricePerSqM'], bins=30, kde=True)\n",
    "plt.title('Distribution of Price Per Sqauare Meter')\n",
    "\n",
    "plt.subplot(3, 2, 6)\n",
    "sns.boxplot(data=data,  x='PricePerSqM')\n",
    "plt.title('Boxplot of Price Per Sqauare Meter')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5AEtDusVYcKT"
   },
   "source": [
    "That's more like it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 770
    },
    "id": "TsnKA2KgFNmg",
    "outputId": "59844fbc-48f0-48a4-babc-f5c603a354fb"
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(10, 8))\n",
    "corr = data.corr(numeric_only=True)\n",
    "sns.heatmap(corr, mask=np.zeros_like(corr, dtype=bool),\n",
    "            cmap=sns.diverging_palette(220, 10, as_cmap=True),\n",
    "            square=True, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y3S0Tg8Buq7W"
   },
   "outputs": [],
   "source": [
    "def MAPE(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "mape_scorer = make_scorer(MAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "daHHJuVi3qfx"
   },
   "outputs": [],
   "source": [
    "class MissingBooleanImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        for feature in X_copy.columns:\n",
    "            ser = X_copy[feature].astype(\"boolean\")\n",
    "            X_copy[feature] = ser.fillna(False)\n",
    "        return X_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sPN7fSL6YRy8"
   },
   "outputs": [],
   "source": [
    "ALL_FEATURES=set(data.columns.values.tolist())\n",
    "NUMERICAL_FEATURES={'Price', 'Area', 'PricePerSqM', 'Rooms_num', 'Rent', 'Build_year', 'Floors_num', 'Floor_no'} #[col for col in df.columns if data[col].dtype in ['int', 'float']]\n",
    "CATEGORICAL_FEATURES={'District', 'Market', 'Construction_status'} #[col for col in data.columns if data[col].dtype == 'string']\n",
    "BOOLEAN_FEATURES={'Garage', 'Lift', 'Basement', 'Balcony', 'Garden', 'Terrace'}\n",
    "\n",
    "def get_pipeline(features, estimator):\n",
    "    features_set = set(features)\n",
    "     # preprocessing for numerical columns\n",
    "    numerical_features = list(features_set.intersection(NUMERICAL_FEATURES))\n",
    "    numerical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='mean')),  # replace NaN  values with the mean of the column\n",
    "        #('scaler', StandardScaler())  # standardize\n",
    "    ])\n",
    "    # preprocessing for categorical columns\n",
    "    categorical_features = list(features_set.intersection(CATEGORICAL_FEATURES))\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),  # replace NaN values with the most frequent value of the column\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))     # one-hot encode categorical features\n",
    "    ])\n",
    "\n",
    "    boolean_features = list(BOOLEAN_FEATURES)\n",
    "\n",
    "    # combine preprocessing steps\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_transformer, numerical_features),\n",
    "            ('cat', categorical_transformer, categorical_features),\n",
    "            ('bool', MissingBooleanImputer(), boolean_features)\n",
    "        ])\n",
    "\n",
    "    # define the model\n",
    "\n",
    "    model = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', estimator)\n",
    "    ])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "60FVH64j4UHL"
   },
   "outputs": [],
   "source": [
    "def predict_price_random_forest(data, features, verbose, log):\n",
    "    X = data[features] # features\n",
    "    y = data['Price']  # target\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "    estimator = RandomForestRegressor(random_state=1, max_depth=15, n_estimators=200)\n",
    "    model = get_pipeline(features, estimator)\n",
    "\n",
    "    # train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    train_score = model.score(X_train, y_train)\n",
    "    test_score = model.score(X_test, y_test)\n",
    "\n",
    "    func = np.exp if log else lambda x: x\n",
    "\n",
    "    X_train_predict = func(model.predict(X_train))\n",
    "    X_test_predict  = func(model.predict(X_test))\n",
    "    y_train_scaled  = func(y_train)\n",
    "    y_test_scaled   = func(y_test)\n",
    "    if verbose:\n",
    "        print(f\"Train MAE: {np.mean(np.abs(X_train_predict - y_train_scaled)):.2f}\")\n",
    "        print(f\"Test MAE: {np.mean(np.abs(X_test_predict - y_test_scaled)):.2f}\")\n",
    "        print(f\"Train MAPE: {np.mean(np.abs((X_train_predict - y_train_scaled) / y_train_scaled)):.2f}\")\n",
    "        print(f\"Test MAPE: {np.mean(np.abs((X_test_predict - y_test_scaled) / y_test_scaled)):.2f}\")\n",
    "        print(f\"Train R^2 score: {train_score:.2f}\")\n",
    "        print(f\"Test R^2 score: {test_score:.2f}\")\n",
    "\n",
    "    y_pred = func(model.predict(X_test))\n",
    "    results = X_test.copy()\n",
    "    results['Actual'] = y_test_scaled.astype(int)\n",
    "    results['Predicted'] = y_pred.astype(int)\n",
    "    pd.options.display.max_colwidth = 100\n",
    "    print(results[['Actual', 'Predicted']].join(data['Link']).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NU9Vjy3wWcVu"
   },
   "source": [
    "I'm not using the hyper-parameters found during Grid Search because it barely makes a difference and takes 10 times the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CQvdkyb1vEa8",
    "outputId": "995d6199-7abf-4c9b-c3c8-9699d05544fc"
   },
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "features = ['Area', 'District', 'Market', 'Rooms_num', 'Build_year', 'Garage', 'Lift', 'Basement', 'Balcony', 'Garden', 'Terrace', 'Floors_num', 'Floor_no', 'Construction_status']#, 'Rent']\n",
    "predict_price_random_forest(data, features, True, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "70AiEDG2_x9R"
   },
   "source": [
    "Again, our data is skewed to the right, thus logarithmic transformation will result with data closer to the normal distribution and hopefully a smaller error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OB8yywsssVx5",
    "outputId": "bf852d51-d6ab-4f25-f236-8b8419960cb8"
   },
   "outputs": [],
   "source": [
    "logData = data.copy()\n",
    "logData[list(NUMERICAL_FEATURES)] = logData[list(NUMERICAL_FEATURES)].apply(lambda x: np.log(x + 0.01))\n",
    "predict_price_random_forest(logData, features, True, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-MxW3zlQzEqV"
   },
   "source": [
    "Tuning the hyper-parameters of the RandomForestRegressor through 3-fold cross validation to avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GycE_HiQBKgj"
   },
   "outputs": [],
   "source": [
    "def grid_search(features, data, estimator, param_grid):\n",
    "\n",
    "    model = get_pipeline(features, estimator)\n",
    "\n",
    "    X = data[features]\n",
    "    y = data['Price']\n",
    "\n",
    "    with parallel_backend('threading'):\n",
    "        estim_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, verbose=5, n_jobs=-1)\n",
    "        estim_search.fit(X, y)\n",
    "    return estim_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "1uTgeL0UQjPS",
    "outputId": "a6863e77-3945-4f8b-d325-9e21317601d5"
   },
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(random_state=1)\n",
    "n_estimators = np.concatenate(([50, 100], np.arange(start=200, stop=2100, step=400)))\n",
    "max_depth = [None, 5, 6, 7] + [int(x) for x in np.arange(start=10, stop=110, step=30)]\n",
    "\n",
    "param_grid = {\n",
    "    'regressor__n_estimators':  n_estimators,\n",
    "    'regressor__max_depth': max_depth,\n",
    "}\n",
    "search = grid_search(features, logData, rf, param_grid)\n",
    "results = pd.DataFrame(search.cv_results_)\n",
    "display(results[['param_regressor__n_estimators',\n",
    "                 'param_regressor__max_depth',\n",
    "                 'mean_test_score',\n",
    "                 'std_test_score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kfxelkD3Qg-O",
    "outputId": "a0d2b1cd-1a1f-492f-dc90-9c2d43840438"
   },
   "outputs": [],
   "source": [
    "gb = GradientBoostingRegressor(random_state=1)\n",
    "learning_rate = np.linspace(0.1, 1.0, num=10)\n",
    "n_estimators = np.concatenate(([50, 100], np.arange(start=200, stop=2100, step=200)))\n",
    "\n",
    "param_grid = {\n",
    "    'regressor__learning_rate': learning_rate,\n",
    "    'regressor__n_estimators':  n_estimators,\n",
    "}\n",
    "search = grid_search(features + ['Rent'], logData, gb, param_grid)\n",
    "results = pd.DataFrame(search.cv_results_)\n",
    "display(results[['param_regressor__n_estimators',\n",
    "                 'param_regressor__learning_rate',\n",
    "                 'mean_test_score',\n",
    "                 'std_test_score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xb0_uUiFCvdM",
    "outputId": "2ff85eed-fa2b-4223-9455-bfcf305c34c5"
   },
   "outputs": [],
   "source": [
    "def predict_price_gradient_boosting(data, features, verbose, log):\n",
    "    X = data[features]\n",
    "    y = data['Price']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "    gb = GradientBoostingRegressor(learning_rate=0.2, n_estimators=1000)\n",
    "    model = get_pipeline(features, gb)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    train_score = model.score(X_train, y_train)\n",
    "    test_score = model.score(X_test, y_test)\n",
    "\n",
    "    func = np.exp if log else lambda x: x\n",
    "\n",
    "    X_train_predict = func(model.predict(X_train))\n",
    "    X_test_predict  = func(model.predict(X_test))\n",
    "    y_train_scaled  = func(y_train)\n",
    "    y_test_scaled   = func(y_test)\n",
    "    if verbose:\n",
    "        print(f\"Train MAE: {np.mean(np.abs(X_train_predict - y_train_scaled)):.2f}\")\n",
    "        print(f\"Test MAE: {np.mean(np.abs(X_test_predict - y_test_scaled)):.2f}\")\n",
    "        print(f\"Train MAPE: {np.mean(np.abs((X_train_predict - y_train_scaled) / y_train_scaled)):.2f}\")\n",
    "        print(f\"Test MAPE: {np.mean(np.abs((X_test_predict - y_test_scaled) / y_test_scaled)):.2f}\")\n",
    "        print(f\"Train R^2 score: {train_score:.2f}\")\n",
    "        print(f\"Test R^2 score: {test_score:.2f}\")\n",
    "\n",
    "    y_pred = func(model.predict(X_test))\n",
    "    results = X_test.copy()\n",
    "    results['Actual'] = y_test_scaled.astype(int)\n",
    "    results['Predicted'] = y_pred.astype(int)\n",
    "    pd.options.display.max_colwidth = 100\n",
    "    print(results[['Actual', 'Predicted']].join(data['Link']).head(10))\n",
    "\n",
    "predict_price_gradient_boosting(logData, features + ['Rent'], True, True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
